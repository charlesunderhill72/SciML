{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOisFafygG66PBCC8Hoqjb0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Problem 2"],"metadata":{"id":"BhZnLllgjNfz"}},{"cell_type":"markdown","source":["I originally wanted to do a diffusion model for this problem, but I am running out of time and I am not condfident that I will get it to work by the deadline. So, I will reuse the CVAE architecture I used in problem 1 for autoregressive purposes."],"metadata":{"id":"RQbTlzcaU4e3"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"-lYGDT7rVOAB","executionInfo":{"status":"ok","timestamp":1742619459891,"user_tz":420,"elapsed":920,"user":{"displayName":"Charlie Underhill","userId":"18173088508470112197"}},"outputId":"28749424-554a-4d5f-915e-daf946bd712c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"qMSviMo1CtjB","executionInfo":{"status":"ok","timestamp":1742619464135,"user_tz":420,"elapsed":4244,"user":{"displayName":"Charlie Underhill","userId":"18173088508470112197"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","kernel_size = 4 # (4, 4) kernel\n","init_channels = 8 # initial number of filters\n","image_channels = 2\n","latent_dim = 16 # latent dimension for sampling"]},{"cell_type":"markdown","source":["This is a modified CVAE architecture from problem 1 to allow for concatenating the previous time step with the latent space."],"metadata":{"id":"KeH2tjnwcqKw"}},{"cell_type":"code","source":["class ConvVAE(nn.Module):\n","    def __init__(self, image_channels=2, init_channels=32, kernel_size=3, latent_dim=64, additional_data_dim=2*128*256):\n","        super(ConvVAE, self).__init__()\n","\n","        # Encoder\n","        self.enc1 = nn.Conv2d(image_channels, init_channels, kernel_size=kernel_size, stride=2, padding=1)  # Output: [batch, 32, 64, 128]\n","        self.enc2 = nn.Conv2d(init_channels, init_channels * 2, kernel_size=kernel_size, stride=2, padding=1)  # Output: [batch, 64, 32, 64]\n","        self.enc3 = nn.Conv2d(init_channels * 2, init_channels * 4, kernel_size=kernel_size, stride=2, padding=1)  # Output: [batch, 128, 16, 32]\n","        self.enc4 = nn.Conv2d(init_channels * 4, 256, kernel_size=kernel_size, stride=2, padding=1)  # Output: [batch, 256, 8, 16]\n","\n","        # Latent space\n","        self.fc_mu = nn.Linear(256 * 8 * 16, latent_dim)\n","        self.fc_log_var = nn.Linear(256 * 8 * 16, latent_dim)\n","        self.fc2 = nn.Linear(latent_dim + additional_data_dim, 256 * 8 * 16)  # Adjusted for concatenated input size\n","\n","        # Decoder\n","        self.dec1 = nn.ConvTranspose2d(256, init_channels * 4, kernel_size=kernel_size, stride=2, padding=1, output_padding=1)  # Output: [batch, 128, 16, 32]\n","        self.dec2 = nn.ConvTranspose2d(init_channels * 4, init_channels * 2, kernel_size=kernel_size, stride=2, padding=1, output_padding=1)  # Output: [batch, 64, 32, 64]\n","        self.dec3 = nn.ConvTranspose2d(init_channels * 2, init_channels, kernel_size=kernel_size, stride=2, padding=1, output_padding=1)  # Output: [batch, 32, 64, 128]\n","        self.dec4 = nn.ConvTranspose2d(init_channels, image_channels, kernel_size=kernel_size, stride=2, padding=1, output_padding=1)  # Output: [batch, 2, 128, 256]\n","\n","    def reparameterize(self, mu, log_var):\n","        std = torch.exp(0.5 * log_var)\n","        eps = torch.randn_like(std)\n","        return mu + eps * std\n","\n","    def forward(self, x, additional_data):\n","        # Encoding\n","        x = F.relu(self.enc1(x))\n","        x = F.relu(self.enc2(x))\n","        x = F.relu(self.enc3(x))\n","        x = F.relu(self.enc4(x))\n","\n","        # Flatten and pass through fully connected layers\n","        batch_size = x.size(0)\n","        x = x.view(batch_size, -1)  # Flatten\n","        mu = self.fc_mu(x)\n","        log_var = self.fc_log_var(x)\n","\n","        # Reparameterization trick\n","        z = self.reparameterize(mu, log_var)\n","\n","        # Flatten the additional data (2, 128, 256) to (batch_size, 2 * 128 * 256)\n","        additional_data_flat = additional_data.view(batch_size, -1)\n","\n","        # Concatenate the latent vector `z` with the additional data\n","        z = torch.cat((z, additional_data_flat), dim=1)\n","\n","        # Pass the concatenated vector through the fully connected layer\n","        z = F.relu(self.fc2(z))  # Reduce the combined vector size to [batch_size, 256 * 8 * 16]\n","        z = z.view(-1, 256, 8, 16)  # Reshape to [batch_size, 256, 8, 16]\n","\n","        # Decoder\n","        x = F.relu(self.dec1(z))\n","        x = F.relu(self.dec2(x))\n","        x = F.relu(self.dec3(x))\n","        reconstruction = torch.sigmoid(self.dec4(x))\n","\n","        return reconstruction, mu, log_var\n","\n","\n","\n","# Inference: After training, the model can be used like this:\n","def predict_next_time_step(model, previous_time_step_data):\n","    \"\"\"\n","    Function to predict the next time step given the previous time step data (geopotential).\n","\n","    model: The trained ConvVAE model.\n","    previous_time_step_data: Geopotential at the previous time step (shape: batch_size, 2, 91, 180).\n","\n","    Returns: Reconstructed geopotential for the next time step.\n","    \"\"\"\n","    model.eval()  # Set the model to evaluation mode\n","\n","    # Ensure the input data is a tensor\n","    previous_time_step_data = torch.tensor(previous_time_step_data).float()\n","\n","    # No need for labels, just pass the previous time step data as additional data\n","    with torch.no_grad():\n","        reconstructed_data, _, _ = model(previous_time_step_data, previous_time_step_data)\n","\n","    return reconstructed_data\n"],"metadata":{"id":"5gCjRmQNGR5O","executionInfo":{"status":"ok","timestamp":1742619464169,"user_tz":420,"elapsed":26,"user":{"displayName":"Charlie Underhill","userId":"18173088508470112197"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["I think this will work if the additional data from the previous time step is flattened."],"metadata":{"id":"NujPExCfdxSi"}},{"cell_type":"code","source":["import xarray as xr\n","\n","data_root = \"/content/drive/MyDrive/Colab Notebooks/data_AM160_final/\"\n","\n","data_1979 = xr.open_dataset(data_root + \"z1979.nc\")\n","data_1980 = xr.open_dataset(data_root + \"z1980.nc\")\n","data_1981 = xr.open_dataset(data_root + \"z1981.nc\")\n","data_1983 = xr.open_dataset(data_root + \"z1983.nc\")\n","data_list = [data_1979, data_1980, data_1981, data_1983]\n","data_list_np = [dataset[\"z\"].values for dataset in data_list]"],"metadata":{"id":"E02829VudvXj","executionInfo":{"status":"ok","timestamp":1742619471809,"user_tz":420,"elapsed":7638,"user":{"displayName":"Charlie Underhill","userId":"18173088508470112197"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","X = np.concatenate(data_list_np, axis=0)\n","\n","X_min = np.min(X)\n","X_max = np.max(X)\n","\n","X_norm = (X - X_min) / (X_max - X_min)"],"metadata":{"id":"X59v1Aa6iFRf","executionInfo":{"status":"ok","timestamp":1742619473236,"user_tz":420,"elapsed":1421,"user":{"displayName":"Charlie Underhill","userId":"18173088508470112197"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["X_tensor = torch.tensor(X_norm, dtype=torch.float32)\n","\n","del X, X_norm"],"metadata":{"id":"ZKhLkdEFifsf","executionInfo":{"status":"ok","timestamp":1742619473856,"user_tz":420,"elapsed":619,"user":{"displayName":"Charlie Underhill","userId":"18173088508470112197"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def final_loss(bce_loss, mu, logvar):\n","    \"\"\"\n","    This function will add the reconstruction loss (BCELoss) and the\n","    KL-Divergence.\n","    KL-Divergence = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n","    :param bce_loss: recontruction loss\n","    :param mu: the mean from the latent vector\n","    :param logvar: log variance from the latent vector\n","    \"\"\"\n","    BCE = bce_loss\n","    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n","    return BCE + KLD"],"metadata":{"id":"yxE0cZzZipvK","executionInfo":{"status":"ok","timestamp":1742619473868,"user_tz":420,"elapsed":11,"user":{"displayName":"Charlie Underhill","userId":"18173088508470112197"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Function to calculate the next power of 2 greater than or equal to the size\n","def next_power_of_2(x):\n","    return 2 ** np.ceil(np.log2(x)).astype(int)\n","\n","# Function to pad an image to the next power of 2 in both dimensions\n","def pad_to_power_of_2(x):\n","    batch_size, channels, height, width = x.size()\n","\n","    # Calculate the next power of 2 for height and width\n","    target_height = next_power_of_2(height)\n","    target_width = next_power_of_2(width)\n","\n","    # Calculate padding needed\n","    pad_height = target_height - height\n","    pad_width = target_width - width\n","\n","    # Padding should be applied symmetrically\n","    pad_top = pad_height // 2\n","    pad_bottom = pad_height - pad_top\n","    pad_left = pad_width // 2\n","    pad_right = pad_width - pad_left\n","\n","    # Apply padding\n","    padded_x = F.pad(x, (pad_left, pad_right, pad_top, pad_bottom), mode='constant', value=0)\n","\n","    return padded_x\n","\n","\n","# Pad the input tensor to the next power of 2\n","X_padded = pad_to_power_of_2(X_tensor)\n","print(f\"Padded input size: {X_padded.size()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"SO5upng_i3_R","executionInfo":{"status":"ok","timestamp":1742619474952,"user_tz":420,"elapsed":1082,"user":{"displayName":"Charlie Underhill","userId":"18173088508470112197"}},"outputId":"6d1d518a-c991-40ec-b830-37b468d844f1"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Padded input size: torch.Size([5844, 2, 128, 256])\n"]}]},{"cell_type":"code","source":["X_minus = torch.roll(X_padded, shifts=-1, dims=0)\n","X_minus.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"1854A3V59LGZ","executionInfo":{"status":"ok","timestamp":1742619476014,"user_tz":420,"elapsed":1060,"user":{"displayName":"Charlie Underhill","userId":"18173088508470112197"}},"outputId":"eca6b74a-d3ad-4152-841c-c6e3b401b51a"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([5844, 2, 128, 256])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["torch.sum(X_padded[1] == X_minus[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"mA3RPyGl9lvN","executionInfo":{"status":"ok","timestamp":1742619476042,"user_tz":420,"elapsed":19,"user":{"displayName":"Charlie Underhill","userId":"18173088508470112197"}},"outputId":"4c9ba1b9-650e-4278-e4a4-90a270767949"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(65536)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["import torch.optim as optim\n","# Initialize the network, loss function, and optimizer\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = ConvVAE().to(device)\n","print(\"check\")\n","criterion = nn.BCELoss(reduction='sum')\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","batch_size = 100\n","trainN = 5844\n","# Train the network\n","num_epochs = 50\n","LOSS = []\n","\n","for epoch in range(num_epochs):\n","    for iter in range (0, trainN, batch_size):\n","        if (iter % 1000 == 0):\n","         print('iteration number,',iter)\n","        batch_X = X_padded[iter:iter+batch_size]\n","        batch_X_minus = X_minus[iter:iter+batch_size]\n","        #print(batch_X.size())\n","        optimizer.zero_grad()\n","        outputs = model(batch_X.to(device).float(), batch_X_minus.to(device).float())\n","        reconstruction, mu, log_var = outputs\n","        #print(reconstruction.size())\n","        bce_loss = criterion(reconstruction, batch_X.to(device).float())\n","        loss = final_loss(bce_loss, mu, log_var)\n","        loss.backward()\n","        optimizer.step()\n","    LOSS.append(loss.detach().cpu().numpy())\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"],"metadata":{"id":"klPsm8gWjDzA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["g"],"metadata":{"id":"KZdHpg7ihrQ9"}},{"cell_type":"markdown","source":["g"],"metadata":{"id":"ppE7lC4FhtH_"}},{"cell_type":"markdown","source":["g"],"metadata":{"id":"mWXfveCYhtNn"}},{"cell_type":"markdown","source":["g"],"metadata":{"id":"lpH9GVwrhtQT"}},{"cell_type":"markdown","source":["g"],"metadata":{"id":"Copz22UihtSl"}},{"cell_type":"markdown","source":["g"],"metadata":{"id":"vVKJIqr8htUp"}},{"cell_type":"markdown","source":["g"],"metadata":{"id":"0rqm4An7htW9"}},{"cell_type":"markdown","source":["g"],"metadata":{"id":"0uGDwiTYhtZD"}},{"cell_type":"markdown","source":["g"],"metadata":{"id":"phTElzT7htbQ"}},{"cell_type":"markdown","source":["g"],"metadata":{"id":"j_w6RdmZhtdp"}},{"cell_type":"markdown","source":["g"],"metadata":{"id":"QVjuD5CDhtf7"}},{"cell_type":"markdown","source":["g"],"metadata":{"id":"zlXs-i6ThtiN"}},{"cell_type":"markdown","source":["g"],"metadata":{"id":"hFn1ZFAOhtoZ"}},{"cell_type":"markdown","source":["g"],"metadata":{"id":"KpvhyzEIhtrL"}},{"cell_type":"markdown","source":["g"],"metadata":{"id":"7nsMAhZohtt6"}},{"cell_type":"markdown","source":["g"],"metadata":{"id":"U3GF3J4Shtwr"}},{"cell_type":"markdown","source":["g"],"metadata":{"id":"MGrNfBTQhtza"}},{"cell_type":"markdown","source":["g"],"metadata":{"id":"5Am-0q_Ght1_"}},{"cell_type":"markdown","source":[],"metadata":{"id":"EDTEkAvHjMPi"}},{"cell_type":"code","source":[],"metadata":{"id":"8ykKkfAaBxKT"},"execution_count":null,"outputs":[]}]}